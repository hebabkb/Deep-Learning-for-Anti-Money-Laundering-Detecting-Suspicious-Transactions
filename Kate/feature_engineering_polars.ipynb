{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering 2"
      ],
      "metadata": {
        "id": "pDPK3EGdGAzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import data from Kaggle**"
      ],
      "metadata": {
        "id": "74kaPrLvGKvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Upload the `kaggle.json` file and get ready to download the SAML-D dataset."
      ],
      "metadata": {
        "id": "npjjl1egGJXe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yLmT6_KUFg0G",
        "outputId": "89f42891-d625-469f-ad7a-30be75d5d3a1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-90622019-4e74-4ffc-b7ac-5d37b75572ee\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-90622019-4e74-4ffc-b7ac-5d37b75572ee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. This step sets up your Kaggle API credentials in a secure way so you can access Kaggle datasets programmatically"
      ],
      "metadata": {
        "id": "lByc0G6KGT6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "xFUe4iddGC0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Download dataset from https://www.kaggle.com/datasets/berkanoztas/synthetic-transaction-monitoring-dataset-aml"
      ],
      "metadata": {
        "id": "XnNUT4g0GX8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d berkanoztas/synthetic-transaction-monitoring-dataset-aml"
      ],
      "metadata": {
        "id": "Y2pNgPb_GdhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. This step extracts the contents of a ZIP file using Python's built-in `zipfile` module."
      ],
      "metadata": {
        "id": "D3dmHpIgGf9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"synthetic-transaction-monitoring-dataset-aml.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"synthetic_transaction_data\")"
      ],
      "metadata": {
        "id": "kGUKsMO9GjBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Reads the CSV file named `SAML-D.csv` into a Pandas DataFrame called `df`"
      ],
      "metadata": {
        "id": "AoD3RepZGml1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import polars as pl\n",
        "os.listdir(\"synthetic_transaction_data\")\n",
        "df = pl.read_csv(\"synthetic_transaction_data/SAML-D.csv\")\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "8WIYIfmaGsSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert `Date` and `Time` to `datetime`**"
      ],
      "metadata": {
        "id": "a-gSC4GmGxGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.with_columns(\n",
        "    pl.col(\"Date\").str.strptime(pl.Date, \"%Y-%m-%d\").alias(\"Date\"),\n",
        "    pl.col(\"Time\").str.strptime(pl.Time, \"%H:%M:%S\").alias(\"Time\")\n",
        ")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "cTKw0kMhGx15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.with_columns(pl.col(\"Date\").cast(pl.Datetime))"
      ],
      "metadata": {
        "id": "0zhMf-1hciKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recast integer-based columns**"
      ],
      "metadata": {
        "id": "axbmkcF3HDqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "We recast the integer‑based columns following the logic rules outlined in the paper.\n",
        "\"Explainable Feature Engineering for Multi-class Money Laundering Classification\"\n",
        "This recasting is performed to optimize storage efficiency and reduce overall memory consumption.\"\n",
        "Excluding \"Sender_account\" and \"Receiver_account\" variables.\n",
        "'''\n",
        "\n",
        "def recast(df):\n",
        "    exclude = ['Sender_account', 'Receiver_account']\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col not in exclude:\n",
        "            dtype = df[col].dtype\n",
        "            if dtype in (pl.Int64, pl.Int32):\n",
        "              maxval = df[col].max()\n",
        "              if maxval:\n",
        "                  if maxval < 127:\n",
        "                      df = df.with_columns(df[col].cast(pl.Int8).alias(col))\n",
        "                  elif maxval < 32767:\n",
        "                      df = df.with_columns(df[col].cast(pl.Int16).alias(col))\n",
        "                  elif maxval < 2147483647:\n",
        "                      df = df.with_columns(df[col].cast(pl.Int32).alias(col))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "o5PAreJ2HGUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = recast(df)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "KtSpfi7XHLgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Temporal Features**"
      ],
      "metadata": {
        "id": "75GN1Jg7HRMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def temporal_features(df):\n",
        "\n",
        "    return df.with_columns([\n",
        "        df[\"Date\"].dt.year().alias(\"year\"),\n",
        "        df[\"Date\"].dt.month().alias(\"month\"),\n",
        "        df[\"Date\"].dt.day().alias(\"day_of_month\"),\n",
        "        df[\"Date\"].dt.weekday().alias(\"day_of_week\"),\n",
        "        df[\"Date\"].dt.ordinal_day().alias(\"day_of_year\"),\n",
        "        df[\"Time\"].dt.hour().alias(\"hour\"),\n",
        "        df[\"Time\"].dt.minute().alias(\"minute\"),\n",
        "        df[\"Time\"].dt.second().alias(\"second\"),\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "6PRtFRwAHUP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = temporal_features(df)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "KIf27yg-L5HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transaction Risk Features**"
      ],
      "metadata": {
        "id": "YDdrFAvxMAEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "high_risk_countries = ['Mexico', 'Turkey', 'Morocco', 'UAE']"
      ],
      "metadata": {
        "id": "adWezG5EIyxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def risk_features(df):\n",
        "\n",
        "    return df.with_columns([\n",
        "        (df[\"Payment_currency\"] != df[\"Received_currency\"]).cast(pl.Int8).alias(\"currency_mismatch\"),\n",
        "        (df[\"Payment_type\"] == \"Cross-border\").cast(pl.Int8).alias(\"cross_border\"),\n",
        "        df[\"Sender_bank_location\"].is_in(high_risk_countries).cast(pl.Int8).alias(\"high_risk_sender\"),\n",
        "        df[\"Receiver_bank_location\"].is_in(high_risk_countries).cast(pl.Int8).alias(\"high_risk_receiver\")])"
      ],
      "metadata": {
        "id": "9HcYxaTfHwer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = risk_features(df)\n",
        "df"
      ],
      "metadata": {
        "id": "VlON2D1xJMHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping column Laundering_type\n",
        "df = df.drop(\"Laundering_type\")"
      ],
      "metadata": {
        "id": "bpmRQrJoK_qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rolling window computing**"
      ],
      "metadata": {
        "id": "vQNjUZ2fmMyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "def build_window_features_lazy(\n",
        "    df,\n",
        "    specs,\n",
        "    date_col=\"Date\",\n",
        "    sender_col=\"Sender_account\",\n",
        "    receiver_col=\"Receiver_account\",\n",
        "    amount_col=\"Amount\",\n",
        "    index_name=\"__row_idx\",\n",
        "    label_choice=\"left\",\n",
        "):\n",
        "    lf = df.lazy() if isinstance(df, pl.DataFrame) else df\n",
        "    lf = lf.with_columns(pl.arange(0, pl.len()).over(pl.lit(True)).alias(index_name))\n",
        "    out_lf = lf\n",
        "\n",
        "    for spec in specs:\n",
        "        kind = spec.get(\"kind\", \"rolling\")\n",
        "\n",
        "        if kind == \"rolling\":\n",
        "            # existing rolling logic (no change)\n",
        "            name = spec[\"name\"]\n",
        "            direction = spec[\"type\"]  # \"fanin\" or \"fanout\"\n",
        "            period_days = int(spec[\"period_days\"])\n",
        "            every = spec.get(\"every\", \"1d\")\n",
        "\n",
        "            if direction == \"fanin\":\n",
        "                group_by = receiver_col\n",
        "                agg_on = sender_col\n",
        "            else:\n",
        "                group_by = sender_col\n",
        "                agg_on = receiver_col\n",
        "\n",
        "            win_label = label_choice\n",
        "            strategy = \"forward\" if win_label == \"left\" else \"backward\"\n",
        "\n",
        "            right = (\n",
        "                lf\n",
        "                .sort([group_by, date_col])\n",
        "                .group_by_dynamic(\n",
        "                    index_column=date_col,\n",
        "                    every=every,\n",
        "                    period=f\"{period_days}d\",\n",
        "                    group_by=group_by,\n",
        "                    closed=\"both\",\n",
        "                    label=win_label\n",
        "                )\n",
        "                .agg(pl.col(agg_on).n_unique().alias(name))\n",
        "                .sort([group_by, date_col])\n",
        "            )\n",
        "\n",
        "            left = out_lf.sort([group_by, date_col])\n",
        "\n",
        "            out_lf = left.join_asof(\n",
        "                right,\n",
        "                left_on=date_col,\n",
        "                right_on=date_col,\n",
        "                by=group_by,\n",
        "                strategy=strategy,\n",
        "            )\n",
        "\n",
        "        elif kind == \"monthly\":\n",
        "            # existing monthly logic (no change)\n",
        "            name = spec[\"name\"]\n",
        "            side = spec.get(\"side\", \"receive\")\n",
        "            group_col = receiver_col if side == \"receive\" else sender_col\n",
        "\n",
        "            monthly_agg = (\n",
        "                lf\n",
        "                .with_columns(pl.col(date_col).dt.truncate(\"1mo\").alias(\"__month\"))\n",
        "                .group_by([group_col, \"__month\"])\n",
        "                .agg(pl.col(amount_col).sum().alias(name))\n",
        "            )\n",
        "\n",
        "            out_lf = (\n",
        "                out_lf\n",
        "                .with_columns(pl.col(date_col).dt.truncate(\"1mo\").alias(\"__month\"))\n",
        "                .join(monthly_agg, on=[group_col, \"__month\"], how=\"left\")\n",
        "                .drop(\"__month\")\n",
        "            )\n",
        "\n",
        "        elif kind == \"daily_pair_count\":\n",
        "            # NEW: back_and_forth_transfers (exact-match on day + pair)\n",
        "            name = spec[\"name\"]  # e.g., \"back_and_forth_transfers\"\n",
        "            # day key = calendar day (truncate to 1 day)\n",
        "            day_key = \"__day\"\n",
        "            # compute counts per sender/receiver/day using lf (lazy)\n",
        "            pair_daily_agg = (\n",
        "                lf\n",
        "                .with_columns(pl.col(date_col).dt.truncate(\"1d\").alias(day_key))\n",
        "                .group_by([sender_col, receiver_col, day_key])\n",
        "                .agg(pl.len().alias(name))  # .len() counts rows in group\n",
        "            )\n",
        "\n",
        "            # attach day key to working frame and join exact on pair + day\n",
        "            out_lf = (\n",
        "                out_lf\n",
        "                .with_columns(pl.col(date_col).dt.truncate(\"1d\").alias(day_key))\n",
        "                .join(pair_daily_agg, on=[sender_col, receiver_col, day_key], how=\"left\")\n",
        "                .fill_null(0)       # optional: replace nulls with 0\n",
        "                .with_columns(pl.col(name).cast(pl.Int64))  # ensure integer type\n",
        "                .drop(day_key)\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"spec kind must be 'rolling', 'monthly', or 'daily_pair_count'\")\n",
        "\n",
        "    return out_lf"
      ],
      "metadata": {
        "id": "6LN3FoIVnVg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specs = [\n",
        "    {\"name\":\"fanin_30d\", \"kind\":\"rolling\", \"type\":\"fanin\", \"period_days\":30, \"every\":\"1d\"},\n",
        "    {\"name\":\"fanout_30d\", \"kind\":\"rolling\", \"type\":\"fanout\", \"period_days\":30, \"every\":\"1d\"},\n",
        "    {\"name\":\"daily_recieve\", \"kind\":\"rolling\", \"type\":\"fanin\", \"period_days\":1, \"every\":\"1d\"},\n",
        "    #{\"name\":\"daily_receive\", \"kind\":\"daily_unique_count\", \"side\":\"receive\"},\n",
        "    {\"name\":\"monthly_receive\", \"kind\":\"monthly\", \"side\":\"receive\"},\n",
        "    {\"name\":\"monthly_send\",    \"kind\":\"monthly\", \"side\":\"send\"},\n",
        "    {\"name\":\"back_and_forth_transfers\", \"kind\":\"daily_pair_count\"},\n",
        "]\n",
        "lazy_with_features = build_window_features_lazy(df, specs, amount_col=\"Amount\", label_choice=\"left\")\n"
      ],
      "metadata": {
        "id": "wmkt9etgmPJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plan = (\n",
        "    lazy_with_features\n",
        "    .sort([\"Receiver_account\", \"Date\"])\n",
        "    .with_columns([pl.col(\"Receiver_account\").set_sorted(), pl.col(\"Date\").set_sorted()])\n",
        ")\n",
        "df_streamed = plan.collect(engine=\"streaming\")\n",
        "df_final = df_streamed.sort(\"__row_idx\").drop(\"__row_idx\")"
      ],
      "metadata": {
        "id": "G6A31OE2mhZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.head()"
      ],
      "metadata": {
        "id": "vi9NYeZwnaX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**More computation**"
      ],
      "metadata": {
        "id": "TKCUoyPg2pca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "\n",
        "def compute_derived_features_lazy(\n",
        "    lf: pl.LazyFrame,\n",
        "    *,\n",
        "    fanin_col: str = \"fanin_30d\",\n",
        "    fanout_col: str = \"fanout_30d\",\n",
        "    daily_receive_col: str = \"daily_receive\",\n",
        "    monthly_receive_col: str = \"monthly_receive\",\n",
        "    monthly_send_col: str = \"monthly_send\",\n",
        "    amount_col: str = \"Amount\",\n",
        "    sender_col: str = \"Sender_account\",\n",
        "    receiver_col: str = \"Receiver_account\",\n",
        "    index_name: str = \"__row_idx\",\n",
        ") -> pl.LazyFrame:\n",
        "    \"\"\"\n",
        "    Take a LazyFrame and return a LazyFrame with derived features:\n",
        "      - fan_in_out_ratio (safe division, 0 when denom missing or zero)\n",
        "      - fanin_intensity_ratio (fanin_30d / daily_receive, 0 when denom missing or zero)\n",
        "      - amount_dispersion_std (per-sender std of Amount, filled 0 when null)\n",
        "      - sent_to_received_ratio_monthly (monthly_receive / monthly_send, 0 when denom missing or zero)\n",
        "\n",
        "    If `daily_receive` is not present in lf.schema(), it is computed lazily as the\n",
        "    per-receiver unique-senders per calendar day (dt.truncate(\"1d\")) and joined back.\n",
        "    The function is fully lazy; call .collect(...) when ready.\n",
        "    \"\"\"\n",
        "    # ensure lazy input\n",
        "    lf = lf if isinstance(lf, pl.LazyFrame) else lf.lazy()\n",
        "\n",
        "    # Attempt to read schema; if unavailable assume missing and compute\n",
        "    try:\n",
        "        schema = lf.schema()\n",
        "        has_daily = daily_receive_col in schema\n",
        "    except Exception:\n",
        "        has_daily = False\n",
        "\n",
        "    # If daily_receive missing, compute it lazily (exact day bucket of unique senders per receiver)\n",
        "    if not has_daily:\n",
        "        day_key = \"__day_for_daily_receive\"\n",
        "        daily_receive_agg = (\n",
        "            lf\n",
        "            .with_columns(pl.col(\"Date\").dt.truncate(\"1d\").alias(day_key))\n",
        "            .group_by([receiver_col, day_key])\n",
        "            .agg(pl.col(sender_col).n_unique().alias(daily_receive_col))\n",
        "        )\n",
        "        lf = (\n",
        "            lf\n",
        "            .with_columns(pl.col(\"Date\").dt.truncate(\"1d\").alias(day_key))\n",
        "            .join(daily_receive_agg, on=[receiver_col, day_key], how=\"left\")\n",
        "            .drop(day_key)\n",
        "        )\n",
        "\n",
        "    # safe division helper expression\n",
        "    def safe_div_expr(num: str, den: str, out_name: str):\n",
        "        return (\n",
        "            pl.when(pl.col(den).is_null() | (pl.col(den) == 0))\n",
        "              .then(0.0)\n",
        "              .otherwise(pl.col(num).cast(pl.Float64) / pl.col(den).cast(pl.Float64))\n",
        "              .alias(out_name)\n",
        "        )\n",
        "\n",
        "    fan_in_out_expr = safe_div_expr(fanin_col, fanout_col, \"fan_in_out_ratio\")\n",
        "    fanin_intensity_expr = safe_div_expr(fanin_col, daily_receive_col, \"fanin_intensity_ratio\")\n",
        "    sent_to_received_monthly_expr = safe_div_expr(monthly_receive_col, monthly_send_col, \"sent_to_received_ratio_monthly\")\n",
        "\n",
        "    # per-sender std aggregation (lazy) and join back\n",
        "    sender_std_agg = (\n",
        "        lf\n",
        "        .select([sender_col, amount_col])\n",
        "        .group_by(sender_col)\n",
        "        .agg(pl.col(amount_col).std().alias(\"__amount_std\"))\n",
        "    )\n",
        "\n",
        "    out = (\n",
        "        lf\n",
        "        .join(sender_std_agg, on=sender_col, how=\"left\")\n",
        "        .with_columns(\n",
        "            pl.col(\"__amount_std\").cast(pl.Float64).fill_null(0.0).alias(\"amount_dispersion_std\")\n",
        "        )\n",
        "        .drop(\"__amount_std\")\n",
        "        .with_columns([\n",
        "            fan_in_out_expr,\n",
        "            fanin_intensity_expr,\n",
        "            sent_to_received_monthly_expr\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "RkAV9iAoE8ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lazy_with_derived = compute_derived_features_lazy(lazy_with_features)\n",
        "\n",
        "# Before streaming collect: pick a primary grouping ordering that matches your rolling computations.\n",
        "# If most rolling features used Receiver_account then Date, use that; otherwise use the grouping you chose.\n",
        "plan_derived = (\n",
        "    lazy_with_derived\n",
        "    .sort([\"Receiver_account\", \"Date\"])\n",
        "    .with_columns([pl.col(\"Receiver_account\").set_sorted(), pl.col(\"Date\").set_sorted()])\n",
        ")\n",
        "\n",
        "df_streamed = plan_derived.collect(engine=\"streaming\")\n",
        "df_final = df_streamed.sort(\"__row_idx\").drop(\"__row_idx\")"
      ],
      "metadata": {
        "id": "tIg54DSf2xbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.head()"
      ],
      "metadata": {
        "id": "Goy-bWCC3DT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_daily_weekly_transaction_counts(\n",
        "    lf: pl.LazyFrame,\n",
        "    date_col: str = \"Date\",\n",
        "    sender_col: str = \"Sender_account\",\n",
        "    receiver_col: str = \"Receiver_account\",\n",
        "    amount_col: str = \"Amount\",\n",
        ") -> pl.LazyFrame:\n",
        "    \"\"\"\n",
        "    Return a LazyFrame with four new columns:\n",
        "      - daily_receiver_transaction\n",
        "      - weekly_receiver_transaction\n",
        "      - daily_sender_transaction\n",
        "      - weekly_sender_transaction\n",
        "\n",
        "    The function keeps the pipeline lazy: it returns a LazyFrame you can .collect() later.\n",
        "    \"\"\"\n",
        "    # base lazy frame with truncated calendar buckets\n",
        "    base = lf.with_columns(\n",
        "        [\n",
        "            pl.col(date_col).dt.truncate(\"1d\").alias(\"_day\"),\n",
        "            pl.col(date_col).dt.truncate(\"1w\").alias(\"_week\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # aggregations (still lazy)\n",
        "    agg_daily_recv = (\n",
        "        base\n",
        "        .group_by([receiver_col, \"_day\"])\n",
        "        .agg(pl.count(amount_col).alias(\"daily_receiver_transaction\"))\n",
        "    )\n",
        "\n",
        "    agg_weekly_recv = (\n",
        "        base\n",
        "        .group_by([receiver_col, \"_week\"])\n",
        "        .agg(pl.count(amount_col).alias(\"weekly_receiver_transaction\"))\n",
        "    )\n",
        "\n",
        "    agg_daily_sndr = (\n",
        "        base\n",
        "        .group_by([sender_col, \"_day\"])\n",
        "        .agg(pl.count(amount_col).alias(\"daily_sender_transaction\"))\n",
        "    )\n",
        "\n",
        "    agg_weekly_sndr = (\n",
        "        base\n",
        "        .group_by([sender_col, \"_week\"])\n",
        "        .agg(pl.count(amount_col).alias(\"weekly_sender_transaction\"))\n",
        "    )\n",
        "\n",
        "    # join aggregated counts back to the base lazyframe\n",
        "    out = (\n",
        "        base\n",
        "        .join(agg_daily_recv, left_on=[receiver_col, \"_day\"], right_on=[receiver_col, \"_day\"], how=\"left\")\n",
        "        .join(agg_weekly_recv, left_on=[receiver_col, \"_week\"], right_on=[receiver_col, \"_week\"], how=\"left\")\n",
        "        .join(agg_daily_sndr, left_on=[sender_col, \"_day\"], right_on=[sender_col, \"_day\"], how=\"left\")\n",
        "        .join(agg_weekly_sndr, left_on=[sender_col, \"_week\"], right_on=[sender_col, \"_week\"], how=\"left\")\n",
        "        .with_columns(\n",
        "            [\n",
        "                pl.coalesce([\"daily_receiver_transaction\", pl.lit(0)]).cast(pl.Int64),\n",
        "                pl.coalesce([\"weekly_receiver_transaction\", pl.lit(0)]).cast(pl.Int64),\n",
        "                pl.coalesce([\"daily_sender_transaction\", pl.lit(0)]).cast(pl.Int64),\n",
        "                pl.coalesce([\"weekly_sender_transaction\", pl.lit(0)]).cast(pl.Int64),\n",
        "            ]\n",
        "        )\n",
        "        .drop([\"_day\", \"_week\"])\n",
        "    )\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "B_fED4s6pVhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_lazy = df_final.lazy()\n",
        "result_lazy = add_daily_weekly_transaction_counts(df_final_lazy)\n",
        "df_result = result_lazy.collect(engine=\"streaming\")"
      ],
      "metadata": {
        "id": "6fezroTYpaBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result.head()"
      ],
      "metadata": {
        "id": "6n1Rapumpq7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = recast(df_result)\n",
        "df_result.head()"
      ],
      "metadata": {
        "id": "mWb8YQu4puMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Circular_transaction_count**"
      ],
      "metadata": {
        "id": "bRrrjU5rp4j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rustworkx"
      ],
      "metadata": {
        "id": "UZmtZjNfslV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rustworkx as rx\n",
        "\n",
        "def circular_count_monthly_rx(pdf, year, month):\n",
        "    edges = list(zip(pdf[\"Sender_account\"], pdf[\"Receiver_account\"]))\n",
        "    if not edges:\n",
        "        return empty_month_frame()\n",
        "\n",
        "    G = rx.PyDiGraph()\n",
        "    node_idx = {}\n",
        "    for u, v in edges:\n",
        "        if u not in node_idx:\n",
        "            node_idx[u] = G.add_node(u)\n",
        "        if v not in node_idx:\n",
        "            node_idx[v] = G.add_node(v)\n",
        "        G.add_edge(node_idx[u], node_idx[v], None)\n",
        "\n",
        "    cycles = rx.simple_cycles(G)\n",
        "\n",
        "    counter = {}\n",
        "    for cyc in cycles:\n",
        "        cyc_nodes = [G[node] for node in cyc]\n",
        "        for node in cyc_nodes:\n",
        "            counter[node] = counter.get(node, 0) + 1\n",
        "\n",
        "    return pl.DataFrame({\n",
        "        \"Sender_account\": list(counter.keys()),\n",
        "        \"circular_transaction_count\": list(counter.values()),\n",
        "        \"year\": [year] * len(counter),\n",
        "        \"month\": [month] * len(counter)\n",
        "    })"
      ],
      "metadata": {
        "id": "wTW9K6-aIKrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over monthly groups\n",
        "results_rx = []\n",
        "for (year, month), group in df.group_by([\"year\", \"month\"]):\n",
        "    res = circular_count_monthly_rx(group, year, month)\n",
        "    if res.height > 0:\n",
        "        results_rx.append(res)\n",
        "\n",
        "# Combine all results\n",
        "out_rx = pl.concat(results_rx, how=\"vertical\") if results_rx else pl.DataFrame()\n",
        "\n",
        "# Join back to original df\n",
        "df_result = (\n",
        "    df.join(out_rx, on=[\"Sender_account\", \"year\", \"month\"], how=\"left\")\n",
        "      .with_columns(\n",
        "          pl.col(\"circular_transaction_count\").fill_null(0)\n",
        "      )\n",
        ")"
      ],
      "metadata": {
        "id": "zBrPO-47syr2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result.head()"
      ],
      "metadata": {
        "id": "QFMUdJ-Js12D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "1b7f66fb-0a3e-4d79-e516-e901cf6694e7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 24)\n",
              "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
              "│ Time     ┆ Date      ┆ Sender_ac ┆ Receiver_ ┆ … ┆ cross_bor ┆ high_risk ┆ high_risk ┆ circular_ │\n",
              "│ ---      ┆ ---       ┆ count     ┆ account   ┆   ┆ der       ┆ _sender   ┆ _receiver ┆ transacti │\n",
              "│ time     ┆ date      ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ on_count  │\n",
              "│          ┆           ┆ i64       ┆ i64       ┆   ┆ i8        ┆ i8        ┆ i8        ┆ ---       │\n",
              "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ i64       │\n",
              "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
              "│ 10:35:19 ┆ 2022-10-0 ┆ 872473195 ┆ 276935542 ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n",
              "│          ┆ 7         ┆ 5         ┆ 6         ┆   ┆           ┆           ┆           ┆           │\n",
              "│ 10:35:20 ┆ 2022-10-0 ┆ 149198906 ┆ 840125533 ┆ … ┆ 1         ┆ 0         ┆ 1         ┆ 0         │\n",
              "│          ┆ 7         ┆ 4         ┆ 5         ┆   ┆           ┆           ┆           ┆           │\n",
              "│ 10:35:20 ┆ 2022-10-0 ┆ 287305149 ┆ 440476700 ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n",
              "│          ┆ 7         ┆           ┆ 2         ┆   ┆           ┆           ┆           ┆           │\n",
              "│ 10:35:21 ┆ 2022-10-0 ┆ 537665243 ┆ 960042022 ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n",
              "│          ┆ 7         ┆ 7         ┆ 0         ┆   ┆           ┆           ┆           ┆           │\n",
              "│ 10:35:21 ┆ 2022-10-0 ┆ 961418617 ┆ 380333697 ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n",
              "│          ┆ 7         ┆ 8         ┆ 2         ┆   ┆           ┆           ┆           ┆           │\n",
              "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 24)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Time</th><th>Date</th><th>Sender_account</th><th>Receiver_account</th><th>Amount</th><th>Payment_currency</th><th>Received_currency</th><th>Sender_bank_location</th><th>Receiver_bank_location</th><th>Payment_type</th><th>Is_laundering</th><th>year</th><th>month</th><th>day_of_month</th><th>day_of_week</th><th>day_of_year</th><th>hour</th><th>minute</th><th>second</th><th>currency_mismatch</th><th>cross_border</th><th>high_risk_sender</th><th>high_risk_receiver</th><th>circular_transaction_count</th></tr><tr><td>time</td><td>date</td><td>i64</td><td>i64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i8</td><td>i32</td><td>i8</td><td>i8</td><td>i8</td><td>i16</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i64</td></tr></thead><tbody><tr><td>10:35:19</td><td>2022-10-07</td><td>8724731955</td><td>2769355426</td><td>1459.15</td><td>&quot;UK pounds&quot;</td><td>&quot;UK pounds&quot;</td><td>&quot;UK&quot;</td><td>&quot;UK&quot;</td><td>&quot;Cash Deposit&quot;</td><td>0</td><td>2022</td><td>10</td><td>7</td><td>5</td><td>280</td><td>10</td><td>35</td><td>19</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>10:35:20</td><td>2022-10-07</td><td>1491989064</td><td>8401255335</td><td>6019.64</td><td>&quot;UK pounds&quot;</td><td>&quot;Dirham&quot;</td><td>&quot;UK&quot;</td><td>&quot;UAE&quot;</td><td>&quot;Cross-border&quot;</td><td>0</td><td>2022</td><td>10</td><td>7</td><td>5</td><td>280</td><td>10</td><td>35</td><td>20</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td></tr><tr><td>10:35:20</td><td>2022-10-07</td><td>287305149</td><td>4404767002</td><td>14328.44</td><td>&quot;UK pounds&quot;</td><td>&quot;UK pounds&quot;</td><td>&quot;UK&quot;</td><td>&quot;UK&quot;</td><td>&quot;Cheque&quot;</td><td>0</td><td>2022</td><td>10</td><td>7</td><td>5</td><td>280</td><td>10</td><td>35</td><td>20</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>10:35:21</td><td>2022-10-07</td><td>5376652437</td><td>9600420220</td><td>11895.0</td><td>&quot;UK pounds&quot;</td><td>&quot;UK pounds&quot;</td><td>&quot;UK&quot;</td><td>&quot;UK&quot;</td><td>&quot;ACH&quot;</td><td>0</td><td>2022</td><td>10</td><td>7</td><td>5</td><td>280</td><td>10</td><td>35</td><td>21</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>10:35:21</td><td>2022-10-07</td><td>9614186178</td><td>3803336972</td><td>115.25</td><td>&quot;UK pounds&quot;</td><td>&quot;UK pounds&quot;</td><td>&quot;UK&quot;</td><td>&quot;UK&quot;</td><td>&quot;Cash Deposit&quot;</td><td>0</td><td>2022</td><td>10</td><td>7</td><td>5</td><td>280</td><td>10</td><td>35</td><td>21</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_result.select('circular_transaction_count').describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "pvyCf2NNyHyb",
        "outputId": "6eec22ee-6b82-49fb-9aab-109c25a49bc9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (9, 2)\n",
              "┌────────────┬────────────────────────────┐\n",
              "│ statistic  ┆ circular_transaction_count │\n",
              "│ ---        ┆ ---                        │\n",
              "│ str        ┆ f64                        │\n",
              "╞════════════╪════════════════════════════╡\n",
              "│ count      ┆ 9.504852e6                 │\n",
              "│ null_count ┆ 0.0                        │\n",
              "│ mean       ┆ 0.404003                   │\n",
              "│ std        ┆ 2.012755                   │\n",
              "│ min        ┆ 0.0                        │\n",
              "│ 25%        ┆ 0.0                        │\n",
              "│ 50%        ┆ 0.0                        │\n",
              "│ 75%        ┆ 0.0                        │\n",
              "│ max        ┆ 17.0                       │\n",
              "└────────────┴────────────────────────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (9, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>circular_transaction_count</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>9.504852e6</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>0.404003</td></tr><tr><td>&quot;std&quot;</td><td>2.012755</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>0.0</td></tr><tr><td>&quot;50%&quot;</td><td>0.0</td></tr><tr><td>&quot;75%&quot;</td><td>0.0</td></tr><tr><td>&quot;max&quot;</td><td>17.0</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df_result.filter(pl.col(\"circular_transaction_count\") >= 1)"
      ],
      "metadata": {
        "id": "cgGGf0jay6D7"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered.height"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW2uJyNey97N",
        "outputId": "e31fad2d-7566-4298-d9a9-2f6c04abacb3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "919026"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered['circular_transaction_count'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "rr74QM79zCze",
        "outputId": "2d8fbc06-36cd-4072-94df-3059854b02d8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (9, 2)\n",
              "┌────────────┬──────────┐\n",
              "│ statistic  ┆ value    │\n",
              "│ ---        ┆ ---      │\n",
              "│ str        ┆ f64      │\n",
              "╞════════════╪══════════╡\n",
              "│ count      ┆ 919026.0 │\n",
              "│ null_count ┆ 0.0      │\n",
              "│ mean       ┆ 4.178325 │\n",
              "│ std        ┆ 5.11158  │\n",
              "│ min        ┆ 1.0      │\n",
              "│ 25%        ┆ 1.0      │\n",
              "│ 50%        ┆ 1.0      │\n",
              "│ 75%        ┆ 9.0      │\n",
              "│ max        ┆ 17.0     │\n",
              "└────────────┴──────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (9, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>value</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>919026.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>4.178325</td></tr><tr><td>&quot;std&quot;</td><td>5.11158</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td></tr><tr><td>&quot;25%&quot;</td><td>1.0</td></tr><tr><td>&quot;50%&quot;</td><td>1.0</td></tr><tr><td>&quot;75%&quot;</td><td>9.0</td></tr><tr><td>&quot;max&quot;</td><td>17.0</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}