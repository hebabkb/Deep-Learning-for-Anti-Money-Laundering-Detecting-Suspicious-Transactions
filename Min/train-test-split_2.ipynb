{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4238221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eba1796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"SAML-D.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9716c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_component_two_phase(\n",
    "    df,\n",
    "    sender_col=\"Sender_account\",\n",
    "    receiver_col=\"Receiver_account\",\n",
    "    label_col=\"is_laundering\",\n",
    "    train_frac=0.8,\n",
    "    random_state=None,\n",
    "):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # 1️⃣ Build graph\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(df[[sender_col, receiver_col]].itertuples(index=False, name=None))\n",
    "    components = list(nx.connected_components(G))\n",
    "\n",
    "    # 2️⃣ Component stats\n",
    "    comp_stats = []\n",
    "    for cid, comp in enumerate(components):\n",
    "        mask = df[sender_col].isin(comp) & df[receiver_col].isin(comp)\n",
    "        sub = df.loc[mask]\n",
    "        n = len(sub)\n",
    "        pos = sub[label_col].sum()\n",
    "        comp_stats.append((cid, n, pos, comp))\n",
    "    comp_df = pd.DataFrame(comp_stats, columns=[\"comp_id\", \"n_tx\", \"n_pos\", \"accounts\"])\n",
    "    comp_df[\"pos_rate\"] = comp_df[\"n_pos\"] / comp_df[\"n_tx\"].replace(0, np.nan)\n",
    "\n",
    "    total_tx = comp_df[\"n_tx\"].sum()\n",
    "    total_pos = comp_df[\"n_pos\"].sum()\n",
    "\n",
    "    target_tx_train = train_frac * total_tx\n",
    "    target_pos_train = train_frac * total_pos\n",
    "    # 3️⃣ Sort components by descending positive rate\n",
    "    comp_df = comp_df.sample(frac=1, random_state=random_state) \\\n",
    "                 .sort_values([\"pos_rate\", \"n_tx\"], ascending=[False, False]) \\\n",
    "                 .reset_index(drop=True)\n",
    "\n",
    "    # 4️⃣ Phase 1: allocate high-positive components to meet expected positive counts\n",
    "    train_comps, test_comps = [], []\n",
    "    train_tx = train_pos = 0\n",
    "    test_tx = test_pos = 0\n",
    "\n",
    "    for _, row in comp_df.iterrows():\n",
    "        if row[\"n_pos\"] > 0:\n",
    "            new_train_pos = train_pos + row[\"n_pos\"]\n",
    "            new_test_pos = test_pos + row[\"n_pos\"]\n",
    "            if new_train_pos < target_pos_train:\n",
    "                train_comps.append(row[\"comp_id\"])\n",
    "                train_tx += row[\"n_tx\"]\n",
    "                train_pos += row[\"n_pos\"]\n",
    "            elif new_test_pos < total_pos - target_pos_train:\n",
    "                test_comps.append(row[\"comp_id\"])\n",
    "                test_tx += row[\"n_tx\"]\n",
    "                test_pos += row[\"n_pos\"]\n",
    "            elif abs(new_test_pos - (total_pos - target_pos_train)) >= abs(new_train_pos - target_pos_train):\n",
    "                train_comps.append(row[\"comp_id\"])\n",
    "                train_tx += row[\"n_tx\"]\n",
    "                train_pos += row[\"n_pos\"]\n",
    "            else:\n",
    "                test_comps.append(row[\"comp_id\"])\n",
    "                test_tx += row[\"n_tx\"]\n",
    "                test_pos += row[\"n_pos\"]\n",
    "        else:\n",
    "            if train_tx < target_tx_train:\n",
    "                train_comps.append(row[\"comp_id\"])\n",
    "                train_tx += row[\"n_tx\"]\n",
    "            else:\n",
    "                test_comps.append(row[\"comp_id\"])\n",
    "                test_tx += row[\"n_tx\"]\n",
    "\n",
    "    # 6️⃣ Extract transactions\n",
    "    comp_to_acc = {r[\"comp_id\"]: r[\"accounts\"] for _, r in comp_df.iterrows()}\n",
    "    train_accounts = set().union(*(comp_to_acc[c] for c in train_comps))\n",
    "    test_accounts = set().union(*(comp_to_acc[c] for c in test_comps))\n",
    "\n",
    "    train_df = df[df[sender_col].isin(train_accounts) & df[receiver_col].isin(train_accounts)]\n",
    "    test_df  = df[df[sender_col].isin(test_accounts)  & df[receiver_col].isin(test_accounts)]\n",
    "\n",
    "    info = {\n",
    "        \"n_train\": len(train_df),\n",
    "        \"n_test\": len(test_df),\n",
    "        \"train_pos_rate\": train_df[label_col].mean(),\n",
    "        \"test_pos_rate\": test_df[label_col].mean(),\n",
    "        \"target_pos_rate\": total_pos / total_tx,\n",
    "        \"train_frac_actual\": len(train_df) / (len(train_df) + len(test_df)),\n",
    "        \"test_pos\":  test_df[label_col].sum(),\n",
    "        \"train_pos\": train_df[label_col].sum()\n",
    "    }\n",
    "\n",
    "    return train_df, test_df, info, comp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0fcbc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_train': 7604163, 'n_test': 1900689, 'train_pos_rate': np.float64(0.001038641596714852), 'test_pos_rate': np.float64(0.001039096874870113), 'target_pos_rate': np.float64(0.0010387326388669703), 'train_frac_actual': 0.8000296059317915, 'test_pos': np.int64(1975), 'train_pos': np.int64(7898)}\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, info, comp_df = split_by_component_two_phase(\n",
    "    data,\n",
    "    sender_col=\"Sender_account\",\n",
    "    receiver_col=\"Receiver_account\",\n",
    "    label_col=\"Is_laundering\",\n",
    "    train_frac=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4e27cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df, test_df, info, comp_df = split_by_component_two_phase(\n",
    "    test_df,\n",
    "    sender_col=\"Sender_account\",\n",
    "    receiver_col=\"Receiver_account\",\n",
    "    label_col=\"Is_laundering\",\n",
    "    train_frac=0.5,\n",
    "    random_state=43\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74a64d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_train': 950572, 'n_test': 950117, 'train_pos_rate': np.float64(0.0010393741873314173), 'test_pos_rate': np.float64(0.0010388194296070904), 'target_pos_rate': np.float64(0.001039096874870113), 'train_frac_actual': 0.5001196934374851, 'test_pos': np.int64(987), 'train_pos': np.int64(988)}\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4420fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\")\n",
    "val_df.to_csv(\"val.csv\")\n",
    "test_df.to_csv(\"test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
